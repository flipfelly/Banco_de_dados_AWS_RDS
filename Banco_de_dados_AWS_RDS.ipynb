{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+25N9hrbWYx30o4jO/k65",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flipfelly/Banco_de_dados_AWS_RDS/blob/main/Banco_de_dados_AWS_RDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando um Banco de Dados Postgres AWS RDS e Populando\n",
        "\n",
        "Para a execução deste código, é necessário que você já tenha uma conta na AWS, um bucket S3, e um banco de dados RDS Postgres criado com acesso público permitido.\n",
        "\n",
        "---\n",
        "\n",
        "## Como criar um banco de dados RDS\n",
        "\n",
        "1. No ambiente AWS, pesquise por **RDS**.\n",
        "2. Clique em **Criar banco de dados**.\n",
        "3. Selecione a opção de criação **Padrão**.\n",
        "4. Em **Opções de mecanismo**, escolha **Postgres** e a versão mais adequada à sua necessidade.\n",
        "5. Em **Modelos**, escolha a opção **Free Tier** (exercício para fins de aprendizado).\n",
        "6. Escolha o modelo **Autogerenciado** e defina uma senha (a qual será referida como **SENHA ESCOLHIDA**).\n",
        "7. **Atenção:** Marque **Sim** na opção **Acesso público**.\n",
        "8. Desmarque **Insights de Performance** para evitar gastos.\n",
        "9. Clique em **Criar banco de dados**.\n",
        "\n",
        "⚠️ **Observação**: Não é necessário alterar as demais configurações, mas revise todas para garantir que você está utilizando o serviço dentro do plano gratuito.\n",
        "\n",
        "---\n",
        "\n",
        "## Como criar um bucket S3\n",
        "\n",
        "1. No ambiente AWS, pesquise por **S3**.\n",
        "2. Clique em **Criar bucket**.\n",
        "3. Dê um nome único globalmente ao seu bucket.\n",
        "4. Desmarque a opção **Bloquear todo o acesso público** (necessário para este exercício).\n",
        "5. Não altere mais nenhuma configuração, a menos que seja necessário para seu caso.\n",
        "6. Clique em **Criar bucket**.\n",
        "\n",
        "### Como colocar arquivos no bucket\n",
        "\n",
        "1. Clique no nome do bucket (presumindo que você já está na página do S3).\n",
        "2. Clique em **Criar uma pasta** e dê um nome a ela (neste exercício, a pasta se chama **imagens**).\n",
        "3. Acesse a pasta criada.\n",
        "4. Clique em **Carregar**.\n",
        "5. Clique em **Adicionar arquivos** e selecione os arquivos desejados (as imagens podem estar em uma pasta local).\n",
        "6. Clique em **Carregar**.\n"
      ],
      "metadata": {
        "id": "ejWKadTwWWQL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5JEpFOpNu9h"
      },
      "outputs": [],
      "source": [
        "import psycopg2 #essa biblioteca ajuda a interagir com o postgres atraves do python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicações sobre a célula:\n",
        "\n",
        "1. **`psycopg2.connect()`**  \n",
        "   Este método da biblioteca `psycopg2` estabelece uma conexão com o banco de dados PostgreSQL. Ele requer os seguintes parâmetros:  \n",
        "   - **`host`**: O endereço do banco de dados. Aqui, você deve inserir o **endpoint** do banco de dados RDS.\n",
        "\n",
        "---\n",
        "\n",
        "        ### Como encontrar o endpoint do banco de dados:\n",
        "          1. Acesse a página do **RDS** no console AWS.  \n",
        "          2. Clique em **Banco de Dados**.  \n",
        "          3. Selecione o seu banco de dados na lista.  \n",
        "          4. Vá até a seção **Segurança e Conexão** e copie o campo **Endpoint**.  \n",
        "\n",
        "        **Pronto, simples, não?**\n",
        "\n",
        "---\n",
        "\n",
        "2. **`database`**  \n",
        "   No momento, use o banco de dados padrão **`postgres`**, pois ainda não criamos o banco de dados desejado. Nesta célula, criaremos um novo banco chamado **`inventario`**.  \n",
        "\n",
        "3. **`user`**  \n",
        "   O usuário configurado ao criar o banco no RDS. Por padrão, ao selecionar o mecanismo PostgreSQL, o usuário é **`postgres`**.\n",
        "\n",
        "4. **`password`**  \n",
        "   A senha criada durante a configuração do banco no modo autogerenciado. Utilize essa senha para a conexão.\n",
        "\n",
        "---\n",
        "\n",
        "### Resolvendo problemas de conexão\n",
        "\n",
        "Caso ocorra algum problema de conexão e você tenha marcado \"Sim\" para acesso público, siga os passos abaixo:\n",
        "\n",
        "1. Clique no seu banco de dados (presumindo que você já está na página do banco de dados no RDS).\n",
        "2. Em **Segurança**, clique no **Grupo de segurança da VPC**.\n",
        "3. Selecione o grupo de segurança associado.\n",
        "4. Acesse **Regras de entrada** → **Editar regras de entrada**.\n",
        "5. Clique em **Adicionar regra**.\n",
        "6. Em **Tipo**, selecione **Todo tráfego**.\n",
        "7. Em **Origem**, selecione **Qualquer local (IPv4)**.\n",
        "8. Salve as regras."
      ],
      "metadata": {
        "id": "-bPqoa9OdgJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "con = psycopg2.connect(host ='database-1.cdk6a8eq4oc8.us-east-1.rds.amazonaws.com', database = 'postgres', user = 'postgres', password = 'sua senha')\n",
        "\n",
        "con.autocommit = True #Garante que as alterações sejam aplicadas imediatamente, sem a necessidade de um `commit` explícito.\n",
        "\n",
        "cur = con.cursor()#Cursor para realizar as consultas\n",
        "\n",
        "cur.execute('create database inventario;') #Envia o comando SQL para criar o banco de dados chamado `inventario`.\n",
        "\n",
        "con.close()\n"
      ],
      "metadata": {
        "id": "oPfQ0jrkN6V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Explicação sobre a célula:\n",
        "- Aqui estamos nos conectando com o banco de dados \"Inventario\", criado na célula anterior.\n",
        "- Criamos tambem uma tabela chamada \"arquivos\""
      ],
      "metadata": {
        "id": "XikBq-m_htjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "con = psycopg2.connect(host ='database-1.cdk6a8eq4oc8.us-east-1.rds.amazonaws.com', database = 'inventario', user = 'postgres', password = 'sua senha')\n",
        "\n",
        "con.autocommit = True\n",
        "\n",
        "cur = con.cursor()\n",
        "\n",
        "cur.execute('create table arquivos (idarquivo INT, nomearquivo VARCHAR(256));')\n",
        "\n",
        "con.close() #Fecha a conexão com o banco de dados, liberando recursos."
      ],
      "metadata": {
        "id": "PDubtdwhR4St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3 #Instalando a biblioteca boto3, que vai nos auxiliar na conexão com os serviços da AWS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjEXVVmDSUDa",
        "outputId": "9c5f0de5-de29-40e2-ae1e-efc53128d4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.36.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting botocore<1.37.0,>=1.36.0 (from boto3)\n",
            "  Downloading botocore-1.36.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
            "  Downloading s3transfer-0.11.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.37.0,>=1.36.0->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.37.0,>=1.36.0->boto3) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.37.0,>=1.36.0->boto3) (1.17.0)\n",
            "Downloading boto3-1.36.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.36.0-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.36.0 botocore-1.36.0 jmespath-1.0.1 s3transfer-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conectando com o Bucket S3\n",
        "\n",
        "Aqui vamos apenas conhecer quais arquivos temos no bucket\n",
        "\n",
        "1. **Configurações iniciais**:\n",
        "   - **`service_name`**: Define o nome do serviço AWS com o qual vamos estabelecer conexão, neste caso, **S3**.  \n",
        "   - **`region_name`**: A região onde o bucket foi criado. No meu exemplo, é a **América do Sul - São Paulo**.  \n",
        "   - **`aws_access_key_id` e `aws_secret_access_key`**: Suas credenciais de acesso da AWS.  \n",
        "   - **`bucket`**: Recebe o nome do bucket criado no S3.  \n",
        "   - **`prefix`**: Define a pasta criada dentro do bucket.\n",
        "\n",
        "---\n",
        "\n",
        "### Como encontrar a `region_name`:\n",
        "1. Acesse a página do **S3** no console AWS.  \n",
        "2. Clique no **bucket** que deseja utilizar.  \n",
        "3. Vá até a aba **Propriedades**.  \n",
        "4. Na seção **Visão Geral do Bucket**, localize **Região AWS**.  \n",
        "5. Copie o código da região.\n",
        "\n",
        "**Pronto! Agora você tem a `region_name` configurada.**\n",
        "\n",
        "---\n",
        "\n",
        "### Como obter suas `credenciais AWS`:\n",
        "1. No canto superior direito da tela, encontre o **nome do usuário**.  \n",
        "2. Clique na **setinha** ao lado do nome.  \n",
        "3. Selecione **Credenciais de Segurança**.  \n",
        "4. Localize a seção **Chaves de Acesso**.  \n",
        "5. Crie uma nova chave de acesso.  \n",
        "6. Salve o arquivo com a chave ou copie os detalhes.\n",
        "\n",
        "⚠️ **Atenção**: Você só poderá visualizar a chave de acesso no momento da criação. Guarde-a em local seguro!\n"
      ],
      "metadata": {
        "id": "XO4esMy-iJxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import psycopg2\n",
        "import io\n",
        "\n",
        "s3 = boto3.resource(service_name = 's3', region_name = 'sa-east-1', aws_access_key_id = 'seu ID de acesso', aws_secret_access_key = 'sua chave de acesso')\n",
        "\n",
        "bucket = 'img-engdados-python'\n",
        "prefix = 'imagens/'\n",
        "\n",
        "for objects_s3 in s3.Bucket(bucket).objects.filter(Prefix = prefix): #percorre os objetos do bucket e nos retorna os nomes\n",
        "  if objects_s3.key.endswith('jpg') or objects_s3.key.endswith('JPG'):\n",
        "    filename = objects_s3.key.split('/')[1]\n",
        "    print(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N2sbyICSebu",
        "outputId": "2bd05818-8fcd-4a9f-9c22-32405d21aac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avenue-g9ad8b9b60_640.jpg\n",
            "dandelion-ge4c90edd8_640.jpg\n",
            "fantasy-g95f970a56_640.jpg\n",
            "garden-g42e486784_640.jpg\n",
            "pink-ge82d54651_640.jpg\n",
            "road-g37132565b_640.jpg\n",
            "road-g41ea28d46_640.jpg\n",
            "sunset-gac16749a1_640.jpg\n",
            "tree-g386d6021c_640.jpg\n",
            "tree-gd34ff2fcb_640.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conectando S3 com PostgreSQL e Inserindo Dados no Banco\n",
        "\n",
        "Aqui utilizamos os codigos das celulas ja executadas, em conjunto, para inserir os dados no banco\n",
        "\n",
        "### Iteração pelos Arquivos do S3:\n",
        "1. Através do **boto3**, acessamos os arquivos do bucket filtrando pelo prefixo definido.  \n",
        "2. Verificamos se os arquivos possuem extensão **.jpg** ou **.JPG**.  \n",
        "3. Extraímos o nome do arquivo usando o método **`split`**.  \n",
        "4. Cada arquivo recebe um identificador único **`id`**, que é incrementado no loop.  \n",
        "5. Executamos um comando **SQL INSERT** no banco para armazenar o ID e o nome do arquivo na tabela **`arquivos`**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Observação:\n",
        "Certifique-se de que:  \n",
        "- A tabela **`arquivos`** foi criada previamente no banco de dados com os campos **`idarquivo`** (INT) e **`nomearquivo`** (VARCHAR).  \n",
        "- Suas credenciais AWS e PostgreSQL estejam corretas e seguras.  \n"
      ],
      "metadata": {
        "id": "jL3inH9zltbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import psycopg2\n",
        "import io\n",
        "\n",
        "s3 = boto3.resource(service_name = 's3', region_name = 'sa-east-1', aws_access_key_id = ' seu id de acesso ', aws_secret_access_key = 'sua chave de acesso')\n",
        "\n",
        "bucket = 'img-engdados-python'\n",
        "prefix = 'imagens/'\n",
        "\n",
        "con = psycopg2.connect(host ='database-1.cdk6a8eq4oc8.us-east-1.rds.amazonaws.com', database = 'inventario', user = 'postgres', password = 'sua senha')\n",
        "\n",
        "con.autocommit = True\n",
        "\n",
        "cur = con.cursor()\n",
        "\n",
        "id = 0\n",
        "\n",
        "for objects_s3 in s3.Bucket(bucket).objects.filter(Prefix = prefix):\n",
        "  if objects_s3.key.endswith('jpg') or objects_s3.key.endswith('JPG'):\n",
        "    filename = objects_s3.key.split('/')[1]\n",
        "    id += 1\n",
        "    cur.execute(\"insert into arquivos (idarquivo, nomearquivo) values (\"+str(id)+\", '\"+filename+\"')\")\n",
        "\n",
        "con.close()"
      ],
      "metadata": {
        "id": "pRa9zIMhUQf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Certificando que a tabela foi preenchida"
      ],
      "metadata": {
        "id": "lt4FMMl_mLRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "con = psycopg2.connect(host ='database-1.cdk6a8eq4oc8.us-east-1.rds.amazonaws.com', database = 'inventario', user = 'postgres', password = 'sua senha')\n",
        "\n",
        "con.autocommit = True\n",
        "\n",
        "cur = con.cursor()\n",
        "\n",
        "cur.execute('select * from arquivos;')\n",
        "\n",
        "recset = cur.fetchall()\n",
        "\n",
        "for rec in recset:\n",
        "  print(rec)\n",
        "\n",
        "con.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dbDfYMgV3uK",
        "outputId": "cf49d25b-0f68-41c4-a0fb-afc53aff49a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 'avenue-g9ad8b9b60_640.jpg')\n",
            "(2, 'dandelion-ge4c90edd8_640.jpg')\n",
            "(3, 'fantasy-g95f970a56_640.jpg')\n",
            "(4, 'garden-g42e486784_640.jpg')\n",
            "(5, 'pink-ge82d54651_640.jpg')\n",
            "(6, 'road-g37132565b_640.jpg')\n",
            "(7, 'road-g41ea28d46_640.jpg')\n",
            "(8, 'sunset-gac16749a1_640.jpg')\n",
            "(9, 'tree-g386d6021c_640.jpg')\n",
            "(10, 'tree-gd34ff2fcb_640.jpg')\n"
          ]
        }
      ]
    }
  ]
}